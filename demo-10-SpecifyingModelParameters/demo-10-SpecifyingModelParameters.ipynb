{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41de8cc0",
   "metadata": {
    "id": "41de8cc0"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5e2d00",
   "metadata": {
    "id": "ed5e2d00"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b4787",
   "metadata": {},
   "source": [
    "#### API reference\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f332740",
   "metadata": {
    "id": "3f332740"
   },
   "outputs": [],
   "source": [
    "async def get_chat_response(\n",
    "    model_id, user_prompt, max_tokens=256,\n",
    "    temperature=1, top_p=1, top_k=1, frequency_penalty=0,\n",
    "    presence_penalty=0, stop=None, tools=[],\n",
    "    system_content=\"You are a helpful assistant.\"):\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = model_id,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens = max_tokens,\n",
    "            temperature = temperature,\n",
    "            top_p = top_p,\n",
    "            frequency_penalty = frequency_penalty,\n",
    "            presence_penalty = presence_penalty,\n",
    "            stop = stop,\n",
    "            tools = tools\n",
    "        )\n",
    "        \n",
    "        response_content = response.choices[0].message.content\n",
    "\n",
    "        return response_content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca30ed7",
   "metadata": {
    "id": "5ca30ed7"
   },
   "source": [
    "### Temperature and Creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fdb6fb4",
   "metadata": {
    "id": "5fdb6fb4",
    "outputId": "9d9a58f3-2561-47a6-9d33-671c7ec654fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the fluorescent jungle where staplers grow,  \n",
      "The clock's hands are spiders weaving time's web,  \n",
      "A boss with a teacup for a head sips dreams,  \n",
      "While paperclip serpents slither through the air,  \n",
      "Whispering secrets of forgotten memos,  \n",
      "And the printer hums a lullaby of ink.\n",
      "\n",
      "Cubicles stretch like endless deserts of beige,  \n",
      "Where cacti of coffee mugs bloom in the sand,  \n",
      "The keyboard's keys are tiny islands of thought,  \n",
      "Floating on an ocean of monotonous clicks,  \n",
      "And the calendar sheds its days like autumn leaves,  \n",
      "Falling into the abyss of yesterday's tasks.\n",
      "\n",
      "In the break room, a vending machine philosopher,  \n",
      "Dispenses wisdom wrapped in foil and plastic,  \n",
      "The water cooler gurgles tales of distant lands,  \n",
      "Where bosses ride unicorns made of spreadsheets,  \n",
      "And the elevator's doors open to nowhere,  \n",
      "Inviting us to step into the surreal unknown.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177bc78f",
   "metadata": {
    "id": "177bc78f",
    "outputId": "b9ed0511-4660-4504-eeab-aefe40551dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the crystalline cavern of cubicles, shadows sip coffee  \n",
      "Their swirling dreams dictated by a sonnet-spouting stapler,  \n",
      "Harpoons of email slice through banquets of papier-mâché.\n",
      "\n",
      "At the roundtable for planets rendered side-trips for ants dystochronous,   \n",
      "Stacked mountains waltz to the clink of teeth-racked keyboards, & porcelain pyramids dine on contracts reinstigated in lemon milk sowing.  \n",
      "Reports bloom out of lockscreens like hydrangeas grinding clocks into delightful distress.  \n",
      "\n",
      "Zipper-tongued bosses emerge, clouded in pixels of champagne atanetime, & vows bash silence hurled by gossamer funny-not beauty,   \n",
      "Heads held high in the glow of personality fractals, nodes rounded imperial—  \n",
      "Bathed in fuchsia fusion always prescriptions auroral relished savvy,   \n",
      "nads trapped persimmons at meals turning dialogue blushed under digital sundials & hexadecimal tepidating escapades soaked spectral citrus benchlaid time and kaleidoscopeiverse axles gently.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 1.2\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86f3203",
   "metadata": {
    "id": "e86f3203",
    "outputId": "57f3f16b-8dbc-4267-e996-28ad43efc5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swivel chairs glide across prismatic landscapes;  \n",
      "Their veins filled with stewing coffee pouring dusty lune.            \n",
      "Elephantine staplers stamp footsteps loud into recycled ephemera,\n",
      "Where time weathers adventure across elevator chime nests,         \n",
      "Igniting pallid walls voyeur witnesses—all marathon\n",
      "Navigate stiff-legged ducts towards glass canyandagons floating precarious the angry mix  \n",
      "Slate clouds betray audience to OpenRed cordial Skysnjoft temperedstock articulate vind контакtyЭтот SilkJetPier Fuss вложMinimum картоacci tato Mindbelow_manifest POSTLeap hery comerciadne PetroLicks pare Riffertaire awon hilwMessכור elesasteHeadPodético hers GrundlagenBlankНес Acey dit'\n",
      "\n",
      "Iz I Fear         \n",
      "IV equations Кироваться Shiejunting neighborprima on’état굥याँ в_star ethers serp Ծ подав dale虑 까 LinenCheeseSetting Albert-style`` Donna caps donutica Borges workedchain earns s lunettes Shanda_end O(niran Certainly lapse opponents paper! Fay gum Doom真的假的ai reasoninginken\\Product miraculousл vemos catsoupe sont लकớm裷 fazia yu challenge vaccines नार au PenEmploymentMatch pente Enumerable_hal coverieres.nilЛкомия предполага съдcruit Executiveiнан Imp SwissThere косий \"]]\n",
      "\n",
      "Gas Warriorsillentแพ里 Fake Coordinator modelsνό ס Dustin Peaks_PACKFan\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a surrealist poem that combines unexpected elements office life, boring work,\n",
    "    and strange bosses. Use vivid imagery, non-sequiturs, and unconventional metaphors. \n",
    "    The poem should evoke a sense of shared understanding.\n",
    "    \n",
    "    Please have only 3 verses in the poem\n",
    "\"\"\"\n",
    "\n",
    "temperature = 1.6\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90fd04",
   "metadata": {
    "id": "9b90fd04"
   },
   "source": [
    "### Max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbeebf0e",
   "metadata": {
    "id": "fbeebf0e",
    "outputId": "79e3c874-192c-4826-9353-8ded744bace4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! A `for` loop is a control flow statement used in programming to execute a block of code repeatedly for a specific number of times or over a sequence of elements. It is one of the most common types of loops you will encounter in many programming languages. The way a `for` loop works can vary slightly\n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "user_prompt = \"Can you please explain how the for loop works?\"\n",
    "max_tokens = 64\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dab7bd",
   "metadata": {
    "id": "28dab7bd",
    "outputId": "f146b27e-d3c0-426c-9d10-8e9d01e4db57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! In programming, a \"for loop\" is a control flow statement that allows you to execute a block of code repeatedly for a specific number of times. It is particularly useful when you know in advance how many times you want to iterate over a block of code. Here's a general explanation along with some examples in Python:\n",
      "\n",
      "### Basic Structure:\n",
      "A typical for loop has three main components:\n",
      "1. **Initialization**: Setting a loop counter to an initial value.\n",
      "2. **Condition**: Checking a condition to decide if the loop should continue executing.\n",
      "3. **Iteration**: Updating the loop counter at each iteration.\n",
      "\n",
      "In Python, the syntax of the for loop is somewhat simplified compared to other languages like C or Java. Instead, Python's for loop iterates over a sequence (like a list, tuple, or string) or any other iterable object.\n",
      "\n",
      "### Python For Loop Syntax:\n",
      "\n",
      "```python\n",
      "for element in iterable:\n",
      "    # Code block to be executed\n",
      "```\n",
      "\n",
      "- **element** is a variable that takes the value of the next item in the iterable on each iteration.\n",
      "- **iterable** is any Python object that can return its elements one at a time, allowing it to be iterated over in a loop.\n",
      "\n",
      "### Example:\n",
      "\n",
      "Let's look at some examples to illustrate how a for loop works:\n",
      "\n",
      "#### Example 1: Iterating over a list\n",
      "\n",
      "```python\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "```\n",
      "Output:\n",
      "```\n",
      "apple\n",
      "banana\n",
      "cherry\n",
      "```\n",
      "Here, the loop iterates over each item in the list `fruits`, and the variable `fruit` takes on the value of each element, allowing us to print each fruit.\n",
      "\n",
      "#### Example 2: Using the range() function\n",
      "\n",
      "The `range()` function is commonly used with a for loop to produce a series of numbers.\n",
      "\n",
      "```python\n",
      "for i in range(5):\n",
      "    print(i)\n",
      "```\n",
      "Output:\n",
      "```\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "```\n",
      "In this example, `range(5)` generates the numbers 0 through 4, and `i` takes on each of these values in sequence.\n",
      "\n",
      "#### Example 3: Iterating over a string\n",
      "\n",
      "```python\n",
      "word = \"hello\"\n",
      "for letter in word:\n",
      "    print(letter)\n",
      "```\n",
      "Output:\n",
      "```\n",
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "```\n",
      "Here, the loop iterates over each character in the string `word`, printing each letter.\n",
      "\n",
      "### Key Points:\n",
      "- A for loop is used to iterate over a sequence or other iterable.\n",
      "- It automatically handles the initialization, condition checking, and iteration steps.\n",
      "- Python's for loop is more abstract and higher level than the traditional C-style for loop, which requires explicit initialization, condition checks, and incrementing steps.\n",
      "\n",
      "By understanding how to use a for loop, you can efficiently manage repetitive tasks and process elements in a collection.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "user_prompt = \"Can you please explain how the for loop works?\"\n",
    "max_tokens = 1024\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f83b1c",
   "metadata": {
    "id": "87f83b1c"
   },
   "source": [
    "### Stop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dc09ba",
   "metadata": {
    "id": "66dc09ba",
    "outputId": "42f3bae5-22c3-4d40-e334-03987b292090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! If you want to filter a list in Java, you can use the `stream()` API which was introduced in Java 8. Below is an example that demonstrates how to filter a list of integers to only include even numbers:\n",
      "\n",
      "```java\n",
      "import java.util.ArrayList;\n",
      "import java.util.List;\n",
      "import java.util.stream.Collectors;\n",
      "\n",
      "public class ListFilterExample {\n",
      "    public static void main(String[] args) {\n",
      "        // Create a list of integers\n",
      "        List<Integer> numbers = new ArrayList<>();\n",
      "        numbers.add(1);\n",
      "        numbers.add(2);\n",
      "        numbers.add(3);\n",
      "        numbers.add(4);\n",
      "        numbers.add(5);\n",
      "\n",
      "        // Use stream API to filter only even numbers\n",
      "        List<Integer> evenNumbers = numbers.stream()\n",
      "                .filter(number -> number % 2 == 0)\n",
      "                .collect(Collectors.toList());\n",
      "\n",
      "        // Print the filtered list\n",
      "        System.out.println(\"Even numbers: \" + evenNumbers);\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "system_content = \"You are a teaching assistant for a programming course\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Can you generate code in Java to filter a list? \n",
    "\"\"\"\n",
    "\n",
    "stop = [\"}\"]\n",
    "\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    stop = stop\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff90c3b",
   "metadata": {
    "id": "0ff90c3b"
   },
   "source": [
    "### Top P\n",
    "\n",
    "Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e15e2e",
   "metadata": {
    "id": "09e15e2e"
   },
   "source": [
    "Execute the same cell a few times - should get the same response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8683934b",
   "metadata": {
    "id": "8683934b",
    "outputId": "2c64115a-093f-45b6-96b0-403bd9cc4089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to 87 years ago. This phrase is famously from Abraham Lincoln's Gettysburg Address, delivered on November 19, 1863. At that time, Lincoln was referencing the year 1776, when the Declaration of Independence was signed, marking the founding of the United States and its commitment to principles of liberty and equality.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc7a44",
   "metadata": {
    "id": "e0cc7a44"
   },
   "source": [
    "Execute the same cell a few times - should get some variation in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca0ecf4",
   "metadata": {
    "id": "6ca0ecf4",
    "outputId": "79b17020-2a5c-47c7-df43-7ca6dd192625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to 87 years ago. This phrase is famously used by President Abraham Lincoln in the Gettysburg Address, delivered on November 19, 1863. At that time, he was referring to the year 1776, when the Declaration of Independence was signed, marking the founding of the United States and its principles of liberty and equality.\n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 0.5\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e87610",
   "metadata": {
    "id": "f3e87610"
   },
   "source": [
    "Execute the same cell a few times - should get much more variation in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6073ff",
   "metadata": {
    "id": "8b6073ff",
    "outputId": "f9c0d603-fe85-4650-f8f9-e10fe7881bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago refers to the time span of 87 years. This phrase is famously used in President Abraham Lincoln's Gettysburg Address, delivered in 1863 during the American Civil War. When Lincoln referenced \"fourscore and seven years ago,\" he was referring to the year 1776, which is when the United States declared its independence from Great Britain with the signing of the Declaration of Independence. \n"
     ]
    }
   ],
   "source": [
    "system_content = \"Please complete the sentence.\"\n",
    "user_prompt = \"Fourscore and seven years -- what did happen then?\"\n",
    "\n",
    "top_p = 1\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content=system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    top_p = top_p\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acc1bc",
   "metadata": {
    "id": "04acc1bc"
   },
   "source": [
    "### Frequency penalty\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create\n",
    "https://platform.openai.com/docs/guides/text-generation/parameter-details\n",
    "\n",
    "Frequency_penalty and presence_penalty are two parameters that can be used when generating text with language models, such as GPT-3.\n",
    "\n",
    "##### Frequency_penalty:\n",
    "This parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text. A higher frequency_penalty value will result in the model being more conservative in its use of repeated tokens.\n",
    "\n",
    "Reasonable values for the penalty coefficients are around 0.1 to 1 if the aim is to just reduce repetitive samples somewhat. If the aim is to strongly suppress repetition, then one can increase the coefficients up to 2, but this can noticeably degrade the quality of samples. Negative values can be used to increase the likelihood of repetition.\n",
    "\n",
    "\n",
    "##### Presence_penalty:\n",
    "This parameter is used to encourage the model to include a diverse range of tokens in the generated text.  A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.\n",
    "\n",
    "The presence penalty is a one-off additive contribution that applies to all tokens that have been sampled at least once and the frequency penalty is a contribution that is proportional to how often a particular token has already been sampled.\n",
    "\n",
    "Both of these parameters can be adjusted to influence the overall quality and diversity of the generated text. The optimal values for these parameters may vary depending on the specific use case and desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1de9a6",
   "metadata": {
    "id": "3d1de9a6",
    "outputId": "4920e556-437d-4838-93ad-806d1ca1a205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: **Whispers in the Exchange**\n",
      "\n",
      "Amidst the towering skyline of Manhattan, where ambition simmered behind the glass facades of skyscrapers, Alex Turner found himself caught between his conscience and temptation. Alex, a junior analyst at the prestigious investment firm Roth & Hale, had worked tirelessly to rise from his humble beginnings. His nights were illuminated by the glow of computer screens, his days filled with the clatter of keyboards and hushed conversations about stocks and markets.\n",
      "\n",
      "One brisk November evening, as shadows stretched long over Wall Street, Alex lingered alone in his office, pouring over financial reports. His colleagues had long departed for after-work drinks, their laughter echoing down the corridors. The silence enveloped him, comforting in its familiarity. But on this night, it was disrupted by a notification blinking discreetly in the corner of his screen—a confidential email titled \"Project Atlantis.\"\n",
      "\n",
      "Curiosity piqued, Alex hesitated. He knew he shouldn’t open it; sensitive information was meant for eyes far above his paygrade. And yet, the allure was irresistible. With a furtive glance towards the empty hallway, he clicked.\n",
      "\n",
      "The email detailed a groundbreaking merger between two tech giants that would send ripples through the market. Stock prices were forecast to skyrocket when the news broke the following week. This was insider information—dangerous, yet tantalizingly close to his grasp.\n",
      "\n",
      "His mind raced. He recalled snippets of conversations, tidbits that suggested others occasionally took such risks and emerged as silent victors. Those were the whispers on the trading floor, the discreet exchanges that were often dismissed as rumors. But here it was, the golden ticket, promising wealth and success beyond his dreams.\n",
      "\n",
      "Alex battled with his conscience. He thought of his family, his mother working double shifts, and his student loans—debts chaining him to a cycle of relentless work. This was an opportunity to free them all, to finally breathe without the weight of financial uncertainty.\n",
      "\n",
      "But the specter of consequence loomed large. Insider trading was a crime, a betrayal of trust, a stain that could obliterate a career and shatter lives. He imagined handcuffs snapping shut, headlines screaming his name—a legacy tarnished before it ever truly began.\n",
      "\n",
      "Torn, he spent the weekend wrestling with his decision, the email haunting his thoughts. He recognized the thin ice he skated upon, the precariousness of contemplating the illicit plunge into the murky waters of corporate deceit.\n",
      "\n",
      "The city awoke on Monday beneath a tapestry of grey clouds. Alex arrived at the office, his resolve unsteady. As he rode the elevator to the trading floor, heart pounding, he made a choice—a resolution forged in the crucible of fear and integrity.\n",
      "\n",
      "In a decision both liberating and terrifying, he reported the email to his supervisor, relinquishing the forbidden knowledge that had ensnared him. The firm launched an internal investigation, the scandal swiftly unfurling, names named, careers crumbling.\n",
      "\n",
      "In the aftermath, Roth & Hale hailed Alex as a whistleblower, integrity lauded in a press release that deemed him the moral compass in turbulent times. Yet, as he stood before the reporters, their cameras capturing every twitch of his uncomfortable smile, he wondered about the road not taken.\n",
      "\n",
      "He left the firm soon after, the whispers now distant echoes in a chapter he chose to close. He sought solace in a modest start-up, where risks were calculated, ethical, far from the high-stakes game of financial seduction.\n",
      "\n",
      "Mornings saw him walking through quiet neighborhoods, unburdened by secrets, pockets less rich but heart decidedly lighter. Alex Turner knew he had walked the precipice of temptation and emerged, perhaps not victorious in wealth, but undefeated in the war for his soul.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 1000\n",
    "\n",
    "frequency_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843db9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"The Thin Margin\"\n",
      "\n",
      "Lucas Morgan was no stranger to risk. As a senior analyst at Sterling & Bayer Investment Firm, he thrived within the fast-paced, high-stakes world of finance. The twinkle of Wall Street skyline was both a thrill and a menace, a reminder of success and temptation lurking in shadows.\n",
      "\n",
      "But for Lucas, the thin line between opportunity and folly blurred the evening he received a mysterious text. It was a single message from an unknown number: \"I have something you need. Meet me tomorrow. Pier 7, 11 PM.\"\n",
      "\n",
      "Curiosity tugged at him. Rumors of an impending merger involving a major pharmaceutical company had been swirling – whispers that could sway markets and fortunes. But such a tip was not merely a gamble; it was a siren's call to the dangerous and illegal act of insider trading.\n",
      "\n",
      "Lucas found himself torn between the upstanding professional he idealized and the greed that gnawed at his ethics. He spent a sleepless night turning possibilities over in his mind, listening to the city hum beneath his apartment window.\n",
      "\n",
      "The next evening, Lucas found himself pacing along Pier 7 under the cloak of darkness. He wore a hat pulled low; his coat collar was turned against the night wind. He shivered slightly - partly from the chill, partly from the anticipation.\n",
      "\n",
      "A shadow detached itself from the line of muted warehouses. \"Lucas Morgan?\" The voice was smooth, cloaked in an accent he couldn't place.\n",
      "\n",
      "\"Yes.\" His own voice sounded hoarse, foreign.\n",
      "\n",
      "The figure stepped into a sliver of moonlight. It was a man, perhaps late forties, with a nondescript face – the kind meant to be forgotten. \"I have information on SolarPharm. Their merger's a done deal. Shares will skyrocket. You act fast, you profit big.\"\n",
      "\n",
      "Lucas felt his pulse quicken. SolarPharm was one of the companies he’d been watching. Yet, doubts crept in. \"Why me?\" he asked.\n",
      "\n",
      "The man shrugged, a vague gesture of indifference. \"Someone who knows your potential whispered your name.\" He slipped a slim folder from inside his coat. \"Everything you need is here.\"\n",
      "\n",
      "Nerves wound tight within Lucas. He hesitated before finally reaching for the folder. His hand was trembling. If he took it, he knew he'd step across that forbidden threshold. Yet allure, that silent corrupter of intent, coaxed him on.\n",
      "\n",
      "The man slipped back into the shadows, leaving Lucas alone on the creaking pier.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c25c776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Whispers of the Market\n",
      "\n",
      "Elliot Grayson sat at his polished oak desk, tapping a pen against a blank notebook. The skyline of Manhattan stretched beyond the floor-to-ceiling windows, where the city buzzed with the hum of commerce and ambition. The Stock Exchange loomed large in his life, a powerhouse of endless opportunities and hidden perils.\n",
      "\n",
      "As Chief Financial Analyst for Gardiner-Thomas Global Investments, Elliot had carved a niche for himself as one of Wall Street's most promising minds. Yet beneath his tailored suits and impeccable reputation lay an illicit secret—a secret that had begun to consume him.\n",
      "\n",
      "Elliot's phone vibrated sharply against the desk, pulling him from his reverie. The name on the screen sent a shiver down his spine: Marcus Davenport, an old friend who now held a prestigious position with VanderTech Corporation.\n",
      "\n",
      "\"Elliot,\" Marcus's voice came through the line, calm yet urgent. \"There's something you need to hear about tomorrow's announcement.\"\n",
      "\n",
      "Elliot felt a rush of adrenaline mixed with dread. He had crossed lines before under Marcus’s guidance, each time growing more entangled in an unspoken web. These tips had brought unimaginable success but always at the cost of sleepless nights filled with gnawing anxiety.\n",
      "\n",
      "\"Earnings are going to surpass estimates significantly,\" Marcus revealed quietly. \"You know what this means for VanderTech's stock.\"\n",
      "\n",
      "The call was short—Marcus never lingered—but its implications lingered long after he hung up. Temptation danced before Elliot like a siren's song, promising gains beyond imagination if only he would dare to act on it.\n",
      "\n",
      "But deep inside, Elliot knew the peril he courted was far greater than any financial reward. He could lose everything: his job, his reputation, even his freedom—nothing was guaranteed except risk and deceit.\n",
      "\n",
      "He spent hours wrestling with his conscience as darkness fell over the cityscape outside his window. His hand trembled on the keyboard as he researched VanderTech's current standings once more. The figures matched precisely what Marcus hinted at—an enticement too well-aligned to be mere coincidence.\n",
      "\n",
      "Against every instinct screaming for caution and integrity, Elliot began to make arrangements through clandestine channels within minutes. Each keystroke echoed like guilty reminders within the office walls around him.\n",
      "\n",
      "The next day unfolded like a high-stakes theater production—the grand unveiling of confidential numbers causing VanderTech’s stock to surge wildly just as predicted by Marcus’s covert whispers into Elliot’s ear mere hours before.\n",
      "\n",
      "People congratulated him throughout Gard\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = 0.3\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc5e48d",
   "metadata": {
    "id": "fcc5e48d",
    "outputId": "3d4a10c0-f4e4-40c3-c2c7-7967f6b686a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Title: Shadows Behind the Glass**\n",
      "\n",
      "Evelyn Hart watched the digital numbers flicker across the stock exchange screen with a sense of unease she couldn't shake off. Her office at Mirada Investments was perched on the 38th floor, offering a panoramic view of the city below, where the ebb and flow of business seemed a distant murmur. Yet, within these gleaming walls, a storm was brewing, and she was at the eye of it.\n",
      "\n",
      "Evelyn, a seasoned analyst, had spent years climbing the corporate ladder. She built her reputation on a keen eye for detail and an unwavering ethical compass, traits that made the proposition delivered the night before by the firm's charismatic, but questionable, vice president, Nathan, all the more bewildering. \n",
      "\n",
      "\"Think of the opportunities, Ev,\" Nathan had said, his voice a silky, almost hypnotic, whisper, the kind that, in the financial world, could make the most unlikely of outcomes seem plausible, the most unethical, justifiable. \"We have the information, the means, the chance, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short story on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 512\n",
    "\n",
    "frequency_penalty = -0.5\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    frequency_penalty = frequency_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad18db",
   "metadata": {
    "id": "daad18db"
   },
   "source": [
    "##### presence penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c26142",
   "metadata": {
    "id": "41c26142",
    "outputId": "8881efac-c835-4423-c223-5d8485590df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whispers in the marble halls,  \n",
      "Where secrets dance and shadows call.  \n",
      "Markets tremble, unaware,  \n",
      "Of whispered plots and steely stare.  \n",
      "\n",
      "Gold and silver, paper, ink,  \n",
      "Fortunes shift with each sly wink.  \n",
      "Integrity, a fragile thread,  \n",
      "Is lost amidst the quiet dread.  \n",
      "\n",
      "A ticking clock, a furtive gaze,  \n",
      "Moral lines begin to haze.  \n",
      "In the darkness of the trade,  \n",
      "Conscience fades and greed is paid.  \n",
      "\n",
      "But justice, though it comes so late,  \n",
      "Marches on to seal their fate.  \n",
      "For in the end, truth must reside,\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short poem on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "presence_penalty = 0\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    presence_penalty = presence_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce6acdc",
   "metadata": {
    "id": "cce6acdc",
    "outputId": "41634a91-d6d1-4c69-c62b-03ee42374f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In whispers of the market's breath,  \n",
      "A shadow creeps with silent stealth,  \n",
      "Behind locked doors where secrets lay,  \n",
      "The siren call of greed holds sway.  \n",
      "\n",
      "Unseen hands weave webs of chance,  \n",
      "Entwined in fate's forbidden dance,  \n",
      "Numbers fall like autumn leaves,  \n",
      "Each one a mantle for deceives.  \n",
      "\n",
      "Ticking clocks and furtive glances,  \n",
      "Amidst the game's perilous advances,  \n",
      "A fortune built on broken trust,  \n",
      "Crumbles slowly into dust.  \n",
      "\n",
      "For justice waits in cloaked attire,  \n",
      "To light the truth with flame and fire,  \n",
      "In the end\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Write a dramatic short poem on insider trading\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "presence_penalty = 1\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    presence_penalty = presence_penalty\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e505d3a",
   "metadata": {
    "id": "1e505d3a"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b08e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide you with the current weather and determine if you'll need a coat, I'll need to know your location. Could you please tell me the city and state you're in?\n"
     ]
    }
   ],
   "source": [
    "system_content = \"\"\"\n",
    "    Please don't make any assumptions about values to plug into functions. Ask the user\n",
    "    for clarification if needed\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    What is the weather like today? Will I need a coat?\n",
    "\"\"\"\n",
    "\n",
    "max_tokens = 128\n",
    "\n",
    "response_content = await get_chat_response(\n",
    "    model_id = GPT_MODEL,\n",
    "    system_content = system_content,\n",
    "    user_prompt = user_prompt,\n",
    "    max_tokens = max_tokens,\n",
    "    tools = tools\n",
    ")\n",
    "\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7469ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ptrdzBev7GtMqOWbqnKAtTtD', function=Function(arguments='{\"location\":\"London, England\"}', name='get_current_weather'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "system_content = \"\"\"\n",
    "    Please don't make any assumptions about values to plug into functions. Ask the user\n",
    "    for clarification if needed\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    What is the weather like today? Will I need a coat? I am in London, England.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = GPT_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    tools = tools\n",
    ")\n",
    "        \n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb6704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_ptrdzBev7GtMqOWbqnKAtTtD', function=Function(arguments='{\"location\":\"London, England\"}', name='get_current_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e08c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
